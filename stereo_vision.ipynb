{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stereo Vision\n",
    "\n",
    "In this notebook, the focus shifts from understanding epipolar geometry to recovering 3D scene information from multiple 2D images. One fundamental problem in multiple view geometry is **triangulation**, which involves determining the 3D location of a point by analyzing its projections in two or more images.\n",
    "\n",
    "## Triangulation\n",
    "**Triangulation Problem with Two Views:**\n",
    "1. Two cameras with known intrinsic parameters `K` and `K'` are considered.\n",
    "2. The relative orientation and translation between these cameras are known, denoted as `R` and `T`.\n",
    "3. A 3D point `P` exists but is unknown, projected onto two images as `p` and `p'`.\n",
    "4. By knowing `K`, `K'`, `R`, and `T`, we can calculate the lines of sight `l` and `l'` from the camera centers `O1` and `O2` to the image locations `p` and `p'`. The 3D point `P` is the intersection of these lines.\n",
    "\n",
    "**Challenges in Triangulation:**\n",
    "In practice, triangulation is more challenging due to several factors:\n",
    "- The observed points `p` and `p'` are subject to noise.\n",
    "- Camera calibration parameters might not be precise.\n",
    "- The intersection of lines of sight may not exist due to noisy measurements.\n",
    "\n",
    "**Linear Triangulation Method:**\n",
    "To address the issues above, a simple linear triangulation method is used. Given two points `p` and `p'` corresponding to a 3D point `P`, we create three constraints for each point. These constraints result in a linear equation of the form `AP = 0`, where `A` is a matrix formed from the constraints. Solving this equation using Singular Value Decomposition (SVD) provides an estimate of the 3D point `P`.\n",
    "\n",
    "**Nonlinear Triangulation:**\n",
    "The linear method has limitations, particularly for projective reconstruction. In real-world scenarios, we often aim to minimize the reprojection error. This leads to a nonlinear minimization problem where we seek `P` that minimizes the sum of squared reprojection errors in all images:\n",
    "\n",
    "```\n",
    "min ∑ (∥MPˆ - p∥²)\n",
    " Pˆ\n",
    "```\n",
    "\n",
    "Solving this nonlinear least squares problem involves methods like the Gauss-Newton algorithm. This algorithm iteratively updates an estimate `Pˆ` by linearizing the residual error and finding the best correction to minimize the reprojection error.\n",
    "\n",
    "**Handling Multiple Views:**\n",
    "This approach naturally extends to multiple views. The linear least squares solution is augmented with the corresponding rows in the `e` vector and `J` matrix for each image, where `e` is the residual vector and `J` is the Jacobian matrix.\n",
    "\n",
    "The Gauss-Newton algorithm is one way to iteratively refine the 3D point estimate. It repeats the linearization and correction steps for a fixed number of iterations or until convergence, with a limit on the number of updates to ensure practicality.\n",
    "\n",
    "While the linear method is suitable for some cases, the nonlinear approach, especially with optimization algorithms like Gauss-Newton, offers more accurate results and handles multiple views effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Affine Structure from Motion**\n",
    "\n",
    "In this section, we dive into the concept of **structure from motion** (SfM), which is the process of simultaneously determining the 3D structure of a scene and the parameters of the cameras capturing that scene. The main goal is to recover both the camera transformation matrices (`Mi`) and the 3D points in the scene (`Xj`) from observations (`xij`) in multiple views.\n",
    "\n",
    "**Affine Structure from Motion Problem:**\n",
    "Before addressing the general SfM problem, we begin with a simpler version assuming affine or weak perspective cameras. In this case, the perspective scaling operation is not present, making mathematical derivations easier.\n",
    "\n",
    "**Affine Camera Model:**\n",
    "For the weak perspective model, the camera matrix `M` simplifies to a form where `v = 0`, which results in the homogeneous coordinate of `MX` being 1. This simplification allows us to express the projection as `AX + b`, where `A` is a 2x3 matrix, and `b` is a 2x1 vector.\n",
    "\n",
    "**Data Centering Step:**\n",
    "In the factorization method for affine SfM, we start with a data centering step. We redefine new coordinates `xˆij` for each image point `xij` by subtracting their centroid `x ̄i`:\n",
    "```\n",
    "xˆij = xij - x ̄i\n",
    "```\n",
    "This step centers the data at the origin in the image plane.\n",
    "\n",
    "**Factorization Method:**\n",
    "The key idea in factorization is to factorize the measurement matrix `D`, which comprises the centered observations, into two matrices: the motion matrix `M` (comprising camera matrices `A` and `b`) and the structure matrix `S` (comprising 3D points `Xj`). This factorization allows us to relate the 3D structure with their observed points compactly.\n",
    "\n",
    "**Singular Value Decomposition (SVD):**\n",
    "The factorization relies on SVD of the measurement matrix `D = UΣVT`. We use the three non-zero singular values from `Σ` to factorize `D` into `U3Σ3V3T`.\n",
    "\n",
    "**Ambiguities in Reconstruction:**\n",
    "A crucial point in SfM is that there is inherent ambiguity in any choice of the factorization `D = MS`. Specifically, any arbitrary, invertible 3x3 matrix `A` can be inserted into the decomposition, which leads to a multiplication of `M` and `S` by the same matrix `A`. This means the solution is underdetermined and requires extra constraints to resolve this affine ambiguity.\n",
    "\n",
    "**Similarity Ambiguity:**\n",
    "Another type of ambiguity in reconstruction is similarity ambiguity, where the reconstruction is correct up to a similarity transform (rotation, translation, and scaling). Calibrated cameras have only similarity ambiguity, meaning the absolute scale of the scene cannot be recovered from images.\n",
    "\n",
    "In summary, SfM involves recovering both camera transformations and 3D scene points from image observations. In the affine SfM problem, we simplify the camera model, center the data, and use factorization methods. However, ambiguities exist in reconstruction, which may require additional constraints or information to resolve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Perspective Structure from Motion**\n",
    "\n",
    "Now, let's delve into the perspective structure from motion problem, which is more general and involves projective cameras (Mi). These cameras are described by 11 degrees of freedom in the form:\n",
    "\n",
    "```\n",
    "Mi = [a11 a12 a13 b1]\n",
    "     [a21 a22 a23 b2]\n",
    "     [a31 a32 a33  1]\n",
    "```\n",
    "\n",
    "It's important to note that solutions for both structure and motion can be determined up to a projective transformation in this general case. This means that you can apply a 4x4 projective transformation H to the motion matrix while also transforming the structure matrix by the inverse transformation H⁻¹, and the observations in the image plane remain the same.\n",
    "\n",
    "**Unknowns in Perspective Structure from Motion:**\n",
    "In this general perspective case, you have 11m + 3n - 15 unknowns (camera parameters and 3D points) and 2mn equations based on observations.\n",
    "\n",
    "**Algebraic Approach:**\n",
    "The algebraic approach aims to compute two camera matrices, M1 and M2, up to a perspective transformation H. The key steps include:\n",
    "\n",
    "1. Compute the fundamental matrix F using the eight-point algorithm.\n",
    "2. Use F to estimate the projective camera matrices M1 and M2.\n",
    "3. Define the structure's 3D point as P and apply H⁻¹ to both camera projection matrices.\n",
    "4. Relate pixel coordinates p and p' to the transformed structure Pe using M1 and M2.\n",
    "\n",
    "**Decomposition Using Fundamental Matrix:**\n",
    "You can decompose F as F = [b]×A, where [b]× represents the skew-symmetric cross product matrix. This decomposition allows you to find b and A:\n",
    "\n",
    "- Compute b as a least square solution of Fb = 0, with ||b|| = 1.\n",
    "- Calculate A as A = -[b]×F.\n",
    "\n",
    "**Factorization of Camera Matrices:**\n",
    "With b and A known, you can determine M1H⁻¹ and M2H⁻¹:\n",
    "\n",
    "- M1H⁻¹ = [I 0]\n",
    "- M2H⁻¹ = [A b]\n",
    "\n",
    "**Geometrical Interpretation of b:**\n",
    "b represents an epipole, which is a point in one image that maps to zero when transformed by the Fundamental matrix.\n",
    "\n",
    "**Determining Motion from the Essential Matrix:**\n",
    "For calibrated cameras, you can use the Essential matrix E, which encodes the extrinsic parameters (rotation and translation). E can be computed from the Fundamental matrix F and the intrinsic matrix K as E = KᵀFK.\n",
    "\n",
    "**Decomposition of E:**\n",
    "Decompose E into [t]×R, where [t]× is skew-symmetric. This decomposition yields two potential rotations (R) and translations (t).\n",
    "\n",
    "- You can choose one of the four possible R, t pairings based on triangulation of points in front of both cameras.\n",
    "\n",
    "**Triangulation for Correct R, t Pair:**\n",
    "Triangulate multiple points, and select the R, t pairing that results in most of these points being in front of both cameras. Triangulation ensures the correct relative orientation and translation between the cameras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
