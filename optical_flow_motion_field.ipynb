{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Understanding Optical Flow and Motion Field\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Optical flow is a concept used in computer vision to describe the apparent movement of pixels in a video due to relative motion between the camera and the objects or scene it's capturing. This movement can occur when either the camera, the scene, or both are in motion. \n",
    "\n",
    "**Figure 1:** In this example, we have a fly rotating in a counter-clockwise direction. Even though the scene is static, the 2D optical flow suggests a clockwise rotation from the fly's point of view.\n",
    "\n",
    "![Figure 1: Optical flow example](images/optical_flow_example.png)\n",
    "\n",
    "### Motion Field\n",
    "\n",
    "It's crucial not to confuse optical flow with the motion field. The motion field is a 2D vector field that describes how 3D motion vectors for points in a scene project onto the observer's image plane. In simpler terms, it tells us how objects in the real world move in the images we capture.\n",
    "\n",
    "**Figure 2:** Here's a simplified 2D example to help us understand the motion field.\n",
    "\n",
    "![Figure 2: Example of a motion field for a 2D scene](images/motion_field_example.png)\n",
    "\n",
    "In a 3D scene, the motion field for a pixel at coordinates (x, y) is given by:\n",
    "\n",
    "```\n",
    "[u, v] = Mx'\n",
    "```\n",
    "\n",
    "Here, M is a matrix containing partial derivatives of pixel displacement with respect to 3D point locations.\n",
    "\n",
    "The motion field is an ideal representation of 3D motion projected onto the 2D image plane, but it's not directly observable. Instead, we estimate optical flow from our noisy video observations.\n",
    "\n",
    "### Optical Flow Computation\n",
    "\n",
    "Optical flow computation is the process of determining how pixels move between consecutive video frames. We want to find the apparent velocity (motion) of each pixel in both the horizontal (x) and vertical (y) directions.\n",
    "\n",
    "In the following sections, we'll delve into the Lucas-Kanade method, a technique for estimating optical flow.\n",
    "\n",
    "### Brightness Constancy and the Optical Flow Constraint\n",
    "\n",
    "The core assumption behind optical flow computation is the brightness constancy assumption. It states that the intensity of an object in consecutive frames remains the same if the object itself hasn't changed. Mathematically, it's expressed as:\n",
    "\n",
    "```\n",
    "I(x, y, t) = I(x + ∆x, y + ∆y, t + ∆t)\n",
    "```\n",
    "\n",
    "Here, ∆x and ∆y represent pixel displacements in the x and y directions between times t and t + ∆t.\n",
    "\n",
    "### Small Motion Assumption and Linearization\n",
    "\n",
    "The small motion assumption allows us to linearize the brightness constancy equation using a Taylor series expansion:\n",
    "\n",
    "```\n",
    "I(x+∆x,y+∆y,t+∆t) ≈ I(x, y, t) + ∂I/∂x ∆x + ∂I/∂y ∆y + ∂I/∂t ∆t\n",
    "```\n",
    "\n",
    "This results in the optical flow constraint equation:\n",
    "\n",
    "```\n",
    "0 = ∂I/∂x ∆x + ∂I/∂y ∆y + ∂I/∂t ∆t\n",
    "```\n",
    "\n",
    "Where ∂I/∂x, ∂I/∂y, and ∂I/∂t are spatial and temporal derivatives of intensity.\n",
    "\n",
    "### Linear System and Aperture Problem\n",
    "\n",
    "We can represent the optical flow constraint as a linear system: Ax = b. Here, ∇I is the spatial gradient of intensity, and u is the optical flow vector we're trying to find.\n",
    "\n",
    "However, this system is under-constrained because there's only one constraint equation for two unknowns (u, v). It only gives us the normal flow, which is the component of u along the gradient direction.\n",
    "\n",
    "**Figure 3:** Visual representation of the solution space for u.\n",
    "\n",
    "![Figure 3: Solution space for u](images/solution_space.png)\n",
    "\n",
    "### Aperture Problem\n",
    "\n",
    "The aperture problem arises because we can't determine the magnitude of pixel movement perpendicular to the gradient direction. This limitation is illustrated in **Figure 4**.\n",
    "\n",
    "**Figure 4:** Visual example of the aperture problem.\n",
    "\n",
    "![Figure 4: Visual example of the aperture problem](images/aperture_problem.png)\n",
    "\n",
    "### Spatial Smoothness Assumption\n",
    "\n",
    "To address this issue, we introduce the spatial smoothness assumption. It assumes that neighboring pixels share the same optical flow if they belong to the same surface in the scene. We create a system of equations by considering multiple pixels in a neighborhood. By minimizing the error, we find the least-squares solution for optical flow.\n",
    "\n",
    "**Figure 5:** The importance of varying spatial structure in solving the aperture problem.\n",
    "\n",
    "![Figure 5: The importance of varying spatial structure](images/spatial_smoothness.png)\n",
    "\n",
    "In practice, the Lucas-Kanade method, in this traditional formulation, might not be robust under certain conditions like large camera motions, occlusions, and violations of its assumptions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
